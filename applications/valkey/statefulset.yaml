apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: valkey
  namespace: valkey
spec:
  # Using Parallel pod management policy for several key reasons:
  # 1. Enables simultaneous pod creation/termination instead of sequential
  # 2. Faster scaling operations as new nodes can join cluster in parallel
  # 3. More efficient cluster formation as nodes don't wait for predecessors
  # 4. Better recovery as replacement pods can be created simultaneously
  # 5. Safe because init-cluster.sh handles race conditions and cluster state checks
  podManagementPolicy: Parallel
  serviceName: valkey
  replicas: 3
  selector:
    matchLabels:
      app: valkey
  template:
    metadata:
      labels:
        app: valkey
    spec:
      # setup configuration, directories and ensure correct permissions
      initContainers:
        - name: init-config
          image: busybox
          command: ["sh", "/scripts/init-config.sh"]
          volumeMounts:
            - name: config
              mountPath: /etc/valkey
              readOnly: true
            - name: scripts
              mountPath: /scripts
            - name: workdir
              mountPath: /config
            - name: data
              mountPath: /data
          env:
            - name: POD_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
      containers:
        # Runs Valkey server
        # Executes cluster initialization
        # Exposes client and cluster ports
        - name: valkey
          image: valkey/valkey:8.1.3
          ports:
            - name: client
              containerPort: 6379
            - name: cluster
              containerPort: 16379
          volumeMounts:
            - name: data
              mountPath: /data
            - name: workdir
              mountPath: /etc/valkey
            - name: scripts
              mountPath: /scripts
          command: ["sh", "-c"]
          args:
            - |
              sh /scripts/init-cluster.sh &
              valkey-server /etc/valkey/valkey.conf
          env:
            - name: POD_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
            - name: HOSTNAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: REPLICAS
              value: "${replicas}"
          securityContext:
            runAsUser: 1000
            runAsGroup: 1000
          # Exports Prometheus metrics
          # Automatically detects cluster mode
        - name: redis-exporter
          image: oliver006/redis_exporter:latest
          securityContext:
            runAsUser: 59000
            runAsGroup: 59000
            allowPrivilegeEscalation: false
            capabilities:
              drop:
                - ALL
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
            - containerPort: 9121
              name: metrics
          env:
            - name: REDIS_ADDR
              value: redis://localhost:6379
            - name: REDIS_EXPORTER_IS_CLUSTER
              value: "true"
      volumes:
        - name: config
          configMap:
            name: valkey
        - name: scripts
          configMap:
            name: valkey
            items:
              - key: init-cluster.sh
                path: init-cluster.sh
              - key: init-config.sh
                path: init-config.sh
            defaultMode: 0755
        - name: workdir
          emptyDir: {}
  volumeClaimTemplates:
    - metadata:
        name: data
      spec:
        accessModes: ["ReadWriteOnce"]
        storageClassName: longhorn-local-wait
        resources:
          requests:
            storage: 10Gi
